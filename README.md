# Goodreads Stats

A comprehensive book data analysis and enrichment system that combines Goodreads export data with external APIs to provide rich genre classification.

## ğŸ—ï¸ Project Structure

```
goodreads_stats/
â”œâ”€â”€ genres/                     # Main book genre enrichment pipeline
â”‚   â”œâ”€â”€ models.py              # Data models (BookInfo, EnrichedBook)
â”‚   â”œâ”€â”€ api_caller.py          # Resilient HTTP client with retries
â”‚   â”œâ”€â”€ fetchers/              # API data fetchers
â”‚   â”‚   â”œâ”€â”€ google_fetcher.py  # Google Books API
â”‚   â”‚   â””â”€â”€ open_library_fetcher.py # Open Library API
â”‚   â”œâ”€â”€ processors/            # Data processors
â”‚   â”‚   â”œâ”€â”€ google_processor.py    # Extract genres from Google Books
â”‚   â”‚   â””â”€â”€ open_library_processor.py # Extract subjects from Open Library
â”‚   â”œâ”€â”€ genre_merger.py        # Merge and normalize genres
â”‚   â”œâ”€â”€ pipeline.py            # Main orchestrator
â”‚   â””â”€â”€ results/               # Pipeline output files
â”œâ”€â”€ api_testing/               # API exploration and testing tools
â”‚   â”œâ”€â”€ models.py              # Basic API testing models
â”‚   â”œâ”€â”€ clients.py             # API client implementations
â”‚   â””â”€â”€ simple_field_explorer.py # Field exploration tool
â”œâ”€â”€ data/                      # Raw data files
â”‚   â””â”€â”€ goodreads_library_export-*.csv
â””â”€â”€ main_pipeline.py           # Main entry point
```

## ğŸš€ Quick Start

### Run the Genre Enrichment Pipeline

```bash
# Run the main pipeline (processes 10 books by default)
python main_pipeline.py
```

### Explore API Fields

```bash
# Explore what fields Google Books API returns for a specific book
python api_testing/simple_field_explorer.py "Consider the Fork"
python api_testing/simple_field_explorer.py "9780465056972"
```

## ğŸ“‹ Features

### Genre Enrichment Pipeline (`genres/`)

The pipeline combines data from Google Books and Open Library APIs to create comprehensive genre classifications:

1. **Data Fetching**: 
   - Google Books: ISBN lookup â†’ title/author fallback
   - Open Library: Edition lookup â†’ Work lookup for maximum data

2. **Processing**: 
   - Extract clean genre/subject lists from raw API responses
   - Handle different response formats and edge cases

3. **Merging**: 
   - Combine and deduplicate genres from both sources
   - Normalize formatting and remove noise

4. **Analysis**: 
   - Source comparison (Google Books vs Open Library)
   - Coverage statistics and overlap analysis
   - Top genres across your library

### API Testing Tools (`api_testing/`)

Development and exploration tools for understanding API capabilities:

- Field exploration for specific books
- Response format analysis
- Rate limiting and error handling testing

## ğŸ“Š Sample Output

```
ğŸ“Š BOOK DATA ENRICHMENT PIPELINE SUMMARY
======================================================================
Total books processed: 10
Google Books success: 8 (80.0%)
Open Library success: 9 (90.0%)
Final enrichment success: 10 (100.0%)

Genre Statistics:
  Average genres per book: 8.3
  Maximum genres: 15
  Books with 0 genres: 0

ğŸ” SOURCE COMPARISON: Google Books vs Open Library
======================================================================
Google Books:
  Average genres per book: 2.1
  Books with data: 8

Open Library:
  Average subjects per book: 6.7
  Books with data: 9
```

## ğŸ”§ Configuration

### Sample Size
Edit `main_pipeline.py` to change the number of books processed:

```python
books = orchestrator.load_goodreads_data(csv_path, sample_size=50)  # Process 50 books
```

### Rate Limiting
Adjust API call frequency:

```python
orchestrator = BookDataOrchestrator(rate_limit=0.5)  # 0.5 calls per second
```

## ğŸ“ Data Files

### Input
- `data/goodreads_library_export-*.csv` - Your Goodreads export file

### Output
- `genres/results/enriched_books.csv` - Detailed results per book
- `genres/results/enrichment_report.json` - Pipeline performance summary

## ğŸ› ï¸ Technical Details

### Architecture
The system uses a modular pipeline architecture:

- **Resilient API Caller**: Handles retries, rate limiting, and error recovery
- **Pluggable Fetchers**: Easy to add new data sources
- **Separate Processing**: Clean separation between fetching and processing
- **Comprehensive Logging**: Track success/failure at each step

### Data Flow
```
Goodreads CSV â†’ BookInfo â†’ Fetch APIs â†’ Process Responses â†’ Merge Genres â†’ EnrichedBook
```

### Error Handling
- Exponential backoff for API failures
- Graceful degradation (use one source if other fails)
- Detailed logging for troubleshooting

## ğŸ“ˆ Extending the System

### Adding New APIs
1. Create fetcher in `genres/fetchers/`
2. Create processor in `genres/processors/`
3. Update pipeline orchestrator

### Custom Genre Normalization
Edit `genres/genre_merger.py` to customize:
- Genre cleaning rules
- Deduplication logic
- Format normalization

### Additional Analysis
Add custom reporting methods to `BookDataOrchestrator` class in `genres/pipeline.py`
